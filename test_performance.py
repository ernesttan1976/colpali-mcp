#!/usr/bin/env python3
"""
Performance Test for ColPali Maximum Performance Mode
"""

import time
import torch
import requests
import json

def test_performance_settings():
    print("ğŸš€ Testing ColPali Maximum Performance Configuration")
    print("=" * 60)
    
    # Test device and memory settings
    print("\nğŸ“± Device Configuration:")
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        print("âœ… Apple Silicon MPS detected")
        expected_batch_size = 16
        expected_mode = "MAXIMUM PERFORMANCE MODE"
    elif torch.cuda.is_available():
        print("âœ… CUDA detected") 
        expected_batch_size = 16
        expected_mode = "MAXIMUM PERFORMANCE MODE"
    else:
        print("âš ï¸  Using CPU")
        expected_batch_size = 4
        expected_mode = "CPU mode"
    
    # Test memory settings
    import os
    mps_ratio = os.environ.get('PYTORCH_MPS_HIGH_WATERMARK_RATIO')
    if mps_ratio is None:
        print("âœ… Memory restrictions removed (PYTORCH_MPS_HIGH_WATERMARK_RATIO not set)")
    else:
        print(f"âš ï¸  Memory restriction still active: {mps_ratio}")
    
    print(f"ğŸ¯ Expected batch size: {expected_batch_size}")
    print(f"ğŸ¯ Expected mode: {expected_mode}")
    
    return True

def test_server_performance():
    """Test actual server performance"""
    print("\nğŸ§ª Testing Server Performance...")
    
    base_url = "http://localhost:8000"
    
    try:
        # Test health endpoint
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code == 200:
            health = response.json()
            print(f"âœ… Server healthy: {health.get('status')}")
            print(f"ğŸ“Š Model loaded: {health.get('model_loaded')}")
            print(f"ğŸ¯ Device: {health.get('device')}")
        else:
            print("âŒ Server not responding")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ Cannot connect to server: {e}")
        print("ğŸ’¡ Make sure to start the server first: python colpali_http_server.py")
        return False
    
    # Test search performance
    print("\nâ±ï¸  Testing search performance...")
    start_time = time.time()
    
    try:
        search_data = {
            "query": "performance test query",
            "top_k": 5
        }
        
        response = requests.post(
            f"{base_url}/search",
            json=search_data,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            task_id = result.get("task_id")
            
            if task_id:
                print(f"ğŸ”„ Search task started: {task_id}")
                
                # Monitor for performance indicators
                for _ in range(60):  # Wait up to 60 seconds
                    try:
                        progress_response = requests.get(f"{base_url}/progress/{task_id}", timeout=5)
                        if progress_response.status_code == 200:
                            progress = progress_response.json().get("progress", {})
                            
                            current_step = progress.get("current_step", "")
                            details = progress.get("details", "")
                            
                            # Look for performance indicators
                            if "MAXIMUM PERFORMANCE" in current_step or "MAXIMUM PERFORMANCE" in details:
                                print("ğŸš€ MAXIMUM PERFORMANCE MODE detected!")
                            
                            if "batch size: 16" in details:
                                print("âœ… Large batch size (16) detected!")
                            elif "batch size: 4" in details:
                                print("â„¹ï¸  Standard batch size (4) - CPU mode")
                            
                            # Check for completion
                            if progress.get("progress", 0) >= 100:
                                elapsed = time.time() - start_time
                                results = progress.get("results", [])
                                print(f"âœ… Search completed in {elapsed:.2f} seconds")
                                print(f"ğŸ“Š Found {len(results)} results")
                                return True
                            
                            if progress.get("error"):
                                print(f"âŒ Search error: {progress['error']}")
                                return False
                        
                        time.sleep(1)
                    except:
                        break
                        
        else:
            print(f"âŒ Search request failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Search test failed: {e}")
        return False
    
    print("â±ï¸  Search test timed out (normal for large documents)")
    return True

def main():
    print("ğŸ”¥ ColPali Maximum Performance Test")
    print("Testing optimizations for speed...")
    
    # Test configuration
    test_performance_settings()
    
    # Test server performance  
    server_ok = test_server_performance()
    
    print("\n" + "=" * 60)
    if server_ok:
        print("ğŸ‰ Performance test completed!")
        print("ğŸš€ Server is running in MAXIMUM PERFORMANCE MODE")
        print("\nğŸ’¡ Tips for maximum speed:")
        print("   - Close other applications to free memory")
        print("   - Use documents with 50-200 pages for optimal batch processing")
        print("   - Monitor system resources during processing")
    else:
        print("âš ï¸  Performance test had issues")
        print("ğŸ’¡ Check server logs for details")

if __name__ == "__main__":
    main()
